{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ethereum Recovery Tool\n",
        "\n",
        "This notebook allows you to run the Ethereum Recovery Tool in both Google Colab and Kaggle.\n",
        "\n",
        "## Step 1: Detect Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def is_running_in_kaggle():\n",
        "    return os.path.exists('/kaggle/input')\n",
        "\n",
        "def is_running_in_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "IN_KAGGLE = is_running_in_kaggle()\n",
        "IN_COLAB = is_running_in_colab()\n",
        "\n",
        "if IN_KAGGLE:\n",
        "    print(\"Running in Kaggle environment\")\n",
        "elif IN_COLAB:\n",
        "    print(\"Running in Google Colab environment\")\n",
        "else:\n",
        "    print(\"Running in another environment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Clone the GitHub Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/sonirn/Timepass.git\n",
        "\n",
        "# Navigate to the repository directory\n",
        "%cd Timepass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Setup the Environment\n",
        "\n",
        "Install Rust and build the recovery tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if IN_KAGGLE:\n",
        "    !chmod +x scripts/kaggle_setup.sh\n",
        "    !./scripts/kaggle_setup.sh\n",
        "elif IN_COLAB:\n",
        "    !chmod +x scripts/colab_setup.sh\n",
        "    !./scripts/colab_setup.sh\n",
        "else:\n",
        "    print(\"Not running in Colab or Kaggle. If you're in Termux, run scripts/setup_rust.sh manually.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Prepare Input Files\n",
        "\n",
        "You can use sample data, create custom files, or upload your own files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy sample files to working directory\n",
        "!cp sample_data/sample_wordlist.txt Wordlist.txt\n",
        "!cp sample_data/sample_addresses.txt eth.txt\n",
        "\n",
        "# Display the first few lines of each file\n",
        "print(\"Wordlist preview:\")\n",
        "!head -n 5 Wordlist.txt\n",
        "print(\"\\nAddresses preview:\")\n",
        "!head -n 2 eth.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 1: Create Custom Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment and modify to create custom files\n",
        "\n",
        "# %%writefile Wordlist.txt\n",
        "# word1\n",
        "# word2\n",
        "# ...\n",
        "# word24\n",
        "\n",
        "# %%writefile eth.txt\n",
        "# 0x1234567890123456789012345678901234567890\n",
        "# 0xabcdefabcdefabcdefabcdefabcdefabcdefabcd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 2: Upload Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "    print(\"Upload your wordlist and addresses files:\")\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        print(f'Uploaded {filename}, size: {len(uploaded[filename])} bytes')\n",
        "elif IN_KAGGLE:\n",
        "    print(\"In Kaggle, you can access files from datasets in /kaggle/input/\")\n",
        "    print(\"Available datasets:\")\n",
        "    !ls -la /kaggle/input\n",
        "    \n",
        "    # Uncomment and modify to copy files from a Kaggle dataset\n",
        "    # !cp /kaggle/input/your-dataset-name/Wordlist.txt .\n",
        "    # !cp /kaggle/input/your-dataset-name/eth.txt ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 3: Use Google Drive (Colab Only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # Uncomment and modify to copy files from Google Drive\n",
        "    # !cp /content/drive/MyDrive/path/to/Wordlist.txt .\n",
        "    # !cp /content/drive/MyDrive/path/to/eth.txt ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Run the Recovery Tool\n",
        "\n",
        "Configure parameters and run the tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration parameters - adjust these based on your needs and available resources\n",
        "wordlist_file = \"Wordlist.txt\"\n",
        "addresses_file = \"eth.txt\"\n",
        "output_file = \"found.txt\"\n",
        "checkpoint_file = \"checkpoint.json\"\n",
        "derivation_paths = \"m/44'/60'/0'/0/0\"\n",
        "chunk_size = 10000  # Reduce this for Termux or limited memory environments\n",
        "threads = 2         # Adjust based on available CPU cores\n",
        "checkpoint_interval = 300  # Seconds between checkpoints\n",
        "verbose = True\n",
        "\n",
        "# Run the tool\n",
        "!chmod +x scripts/run_recovery.sh\n",
        "!./scripts/run_recovery.sh \\\n",
        "  \"$wordlist_file\" \\\n",
        "  \"$addresses_file\" \\\n",
        "  \"$output_file\" \\\n",
        "  \"$checkpoint_file\" \\\n",
        "  \"$derivation_paths\" \\\n",
        "  \"$chunk_size\" \\\n",
        "  \"$threads\" \\\n",
        "  \"$checkpoint_interval\" \\\n",
        "  \"{\"--verbose\" if verbose else \"\"}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Access Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display found results\n",
        "print(\"Found results:\")\n",
        "!cat found.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    # Download results in Colab\n",
        "    from google.colab import files\n",
        "    files.download('found.txt')\n",
        "    files.download('checkpoint.json')\n",
        "elif IN_KAGGLE:\n",
        "    # In Kaggle, create a new dataset with the results\n",
        "    print(\"In Kaggle, you can create a new dataset with your results:\")\n",
        "    print(\"1. Go to the 'Data' tab on the right\")\n",
        "    print(\"2. Click 'Create New Dataset'\")\n",
        "    print(\"3. Add found.txt and checkpoint.json to your dataset\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
